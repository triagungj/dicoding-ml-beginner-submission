{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/triagungj/dicoding-ml-beginner-submission/blob/master/Codes/Clustering%20Submission%20Tri%20Agung%20Jiwandono.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tvAKGat01Sd"
      },
      "source": [
        "# **Penting**\n",
        "- Jangan mengubah atau menambahkan cell text yang sudah disediakan, Anda hanya perlu mengerjakan cell code yang sudah disediakan.\n",
        "- Pastikan seluruh kriteria memiliki output yang sesuai, karena jika tidak ada output dianggap tidak selesai.\n",
        "- Misal, Anda menggunakan df = df.dropna() silakan gunakan df.isnull().sum() sebagai tanda sudah berhasil. Silakan sesuaikan seluruh output dengan perintah yang sudah disediakan.\n",
        "- Pastikan Anda melakukan Run All sebelum mengirimkan submission untuk memastikan seluruh cell berjalan dengan baik.\n",
        "- Pastikan Anda menggunakan variabel df dari awal sampai akhir dan tidak diperbolehkan mengganti nama variabel tersebut.\n",
        "- Hapus simbol pagar (#) pada kode yang bertipe komentar jika Anda menerapkan kriteria tambahan\n",
        "- Biarkan simbol pagar (#) jika Anda tidak menerapkan kriteria tambahan\n",
        "- Pastikan Anda mengerjakan sesuai section yang sudah diberikan tanpa mengubah judul atau header yang disediakan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKi5D9qVVJvY"
      },
      "source": [
        "# **INFORMASI DATASET**\n",
        "\n",
        "Dataset ini menyajikan gambaran mendalam mengenai perilaku transaksi dan pola aktivitas keuangan, sehingga sangat ideal untuk eksplorasi **deteksi penipuan (fraud detection)** dan **identifikasi anomali**. Dataset ini mencakup **2.512 sampel data transaksi**, yang mencakup berbagai atribut transaksi, demografi nasabah, dan pola penggunaan.\n",
        "\n",
        "Setiap entri memberikan wawasan komprehensif terhadap perilaku transaksi, memungkinkan analisis untuk **keamanan finansial** dan pengembangan model prediktif.\n",
        "\n",
        "## Fitur Utama\n",
        "\n",
        "- **`TransactionID`**: Pengidentifikasi unik alfanumerik untuk setiap transaksi.  \n",
        "- **`AccountID`**: ID unik untuk setiap akun, dapat memiliki banyak transaksi.  \n",
        "- **`TransactionAmount`**: Nilai transaksi dalam mata uang, mulai dari pengeluaran kecil hingga pembelian besar.  \n",
        "- **`TransactionDate`**: Tanggal dan waktu transaksi terjadi.  \n",
        "- **`TransactionType`**: Tipe transaksi berupa `'Credit'` atau `'Debit'`.  \n",
        "- **`Location`**: Lokasi geografis transaksi (nama kota di Amerika Serikat).  \n",
        "- **`DeviceID`**: ID perangkat yang digunakan dalam transaksi.  \n",
        "- **`IP Address`**: Alamat IPv4 yang digunakan saat transaksi, dapat berubah untuk beberapa akun.  \n",
        "- **`MerchantID`**: ID unik merchant, menunjukkan merchant utama dan anomali transaksi.  \n",
        "- **`AccountBalance`**: Saldo akun setelah transaksi berlangsung.  \n",
        "- **`PreviousTransactionDate`**: Tanggal transaksi terakhir pada akun, berguna untuk menghitung frekuensi transaksi.  \n",
        "- **`Channel`**: Kanal transaksi seperti `Online`, `ATM`, atau `Branch`.  \n",
        "- **`CustomerAge`**: Usia pemilik akun.  \n",
        "- **`CustomerOccupation`**: Profesi pengguna seperti `Dokter`, `Insinyur`, `Mahasiswa`, atau `Pensiunan`.  \n",
        "- **`TransactionDuration`**: Lama waktu transaksi (dalam detik).  \n",
        "- **`LoginAttempts`**: Jumlah upaya login sebelum transaksi—jumlah tinggi bisa mengindikasikan anomali.\n",
        "\n",
        "Tugas kamu adalah membuat model clustering yang selanjutnya akan digunakan untuk membuat model klasifikasi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**\n",
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning. Semua library yang dibutuhkan harus **import** di **cell** ini, jika ada library yang dijalankan di cell lain maka **submission langsung ditolak**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "sns.set_theme(style='whitegrid')\n",
        "plt.rcParams['figure.dpi'] = 120\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset**\n",
        "Pada tahap ini, Anda perlu memuat dataset ke dalam notebook lalu mengecek informasi dataset sebelum nantinya dilakukan pembersihan. Hal-hal yang perlu dilakukan pada tahapan ini yaitu:\n",
        "1. **Memahami Struktur Data**\n",
        "   - Dataset harus mengambil referensi wajib digunakan (bisa dilihat [Disini](https://drive.google.com/drive/folders/1Zs7VmPZ-jNwsRlMKH65Ea-LApSwx6lKx?usp=drive_link))\n",
        "   - Melakukan loading dataset ke dalam notebook dan menampilkan 5 baris pertama dengan function `head`.\n",
        "   - Tinjau jumlah baris kolom dan jenis data dalam dataset dengan function `info`.  \n",
        "   - Menampilkan statistik deskriptif dataset dengan menjalankan `describe`.\n",
        "   - Pastikan **setiap function tersebut** memiliki **output pada setiap cell** code. Jika tidak **submission langsung ditolak**\n",
        "   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgKXTwx2LMQA"
      },
      "source": [
        "Gunakan code ini untuk melakukan load data secara otomatis tanpa harus download data tersebut secara manual:\n",
        "```python\n",
        "url='https://drive.google.com/uc?id=1gnLO9qvEPqv1uBt1928AcsCmdvzqjC5m'\n",
        "df = pd.read_csv(url)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9d2RyUOuefWa"
      },
      "source": [
        "Penting: pada kriteria pertama hindari penggunaan print() dan display() karena seluruh fungsi yang digunakan sudah memiliki standar output dan menghasilkan output yang diharapkan.\n",
        "\n",
        "Kriteria 1 akan ditolak ketika:\n",
        "- print(__.head())\n",
        "- display(___.head())\n",
        "dst\n",
        "\n",
        "Kriteria 1 akan diterima ketika Anda menggunakan fungsi yang diminta tanpa menambahkan deskripsi apapun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tfuxA86YztE"
      },
      "outputs": [],
      "source": [
        "# Maaf, saya running di local :))\n",
        "# data_path = Path('../Dataset/bank-transactions-dataset.csv')\n",
        "# df = pd.read_csv(data_path)\n",
        "\n",
        "url='https://drive.google.com/uc?id=1gnLO9qvEPqv1uBt1928AcsCmdvzqjC5m'\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [],
      "source": [
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MgRVyMLnR5h"
      },
      "outputs": [],
      "source": [
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN9KsJPonVKT"
      },
      "outputs": [],
      "source": [
        "df.describe(include='all')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNOEZk24uiXu"
      },
      "source": [
        "(Opsional) Memuat Dataset dan Melakukan Exploratory Data Analysis (EDA) [Skilled]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria skilled**\n",
        "\n",
        "**Apabila ingin menerapkan Advanced, pastikan seluruh visualisasi tidak ada yang overlap**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGAJlKExnYAt"
      },
      "outputs": [],
      "source": [
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "corr_matrix = df[numeric_cols].corr(numeric_only=True)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(\n",
        "    corr_matrix,\n",
        "    annot=True,\n",
        "    fmt='.2f',\n",
        "    cmap='Blues',\n",
        "    vmin=-1,\n",
        "    vmax=1,\n",
        "    linewidths=0.5,\n",
        "    annot_kws={'size': 8}\n",
        ")\n",
        "plt.title('Correlation Matrix of Numeric Features')\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcBn9v4Fn8FO"
      },
      "outputs": [],
      "source": [
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "\n",
        "cols = 3\n",
        "rows = (len(numeric_cols) + cols - 1) // cols\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(6 * cols, 3.5 * rows))\n",
        "axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
        "\n",
        "for ax, column in zip(axes, numeric_cols):\n",
        "    sns.histplot(df[column], kde=True, bins=30, ax=ax, color='#4472C4')\n",
        "    ax.set_title(column)\n",
        "    ax.set_xlabel(column)\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "for ax in axes[len(numeric_cols):]:\n",
        "    ax.remove()\n",
        "\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-S35baFuwaP"
      },
      "source": [
        "(Opsional) Memuat Dataset dan Melakukan Exploratory Data Analysis (EDA) [Advanced]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria advanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVIuT8VDokKn"
      },
      "outputs": [],
      "source": [
        "categorical_cols = [\n",
        "    col\n",
        "    for col in df.select_dtypes(include='object').columns\n",
        "    if not any(keyword in col for keyword in ['ID', 'Address', 'Date'])\n",
        "]\n",
        "\n",
        "if categorical_cols:\n",
        "    cols = 2\n",
        "    rows = (len(categorical_cols) + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(7 * cols, 4 * rows))\n",
        "    axes = axes.flatten() if hasattr(axes, 'flatten') else [axes]\n",
        "\n",
        "    for ax, column in zip(axes, categorical_cols):\n",
        "        value_counts = df[column].value_counts().nlargest(15)\n",
        "        sns.barplot(x=value_counts.index, y=value_counts.values, ax=ax, color='#2f5597')\n",
        "        ax.set_title(f'{column} Distribution (Top {len(value_counts)})')\n",
        "        ax.set_xlabel(column)\n",
        "        ax.set_ylabel('Count')\n",
        "        ax.tick_params(axis='x', rotation=45, labelsize=9)\n",
        "\n",
        "    for ax in axes[len(categorical_cols):]:\n",
        "        ax.remove()\n",
        "\n",
        "    plt.tight_layout()\n",
        "else:\n",
        "    print('Tidak ada fitur kategorikal relevan untuk divisualisasikan.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSemyzQHU0On"
      },
      "source": [
        "# **3. Pembersihan dan Pra Pemrosesan Data**\n",
        "\n",
        "Pada tahap ini, Anda akan melakukan **Pembersihan Dataset** untuk menjadikan dataset mudah diintepretasi dan bisa dilatih. Hal-hal yang wajib kamu lakukan yaitu:\n",
        "\n",
        "1. **Mengecek dataset** menggunakan isnull().sum() dan duplicated().sum().\n",
        "2. Melakukan feature scaling menggunakan `MinMaxScaler()` atau `StandardScalar()` untuk fitur numerik.\n",
        "3. Melakukan feature encoding menggunakan `LabelEncoder()` untuk fitur kategorikal.\n",
        "4. Melakukan drop pada kolom id.\n",
        "5. **Ketentuan Cell Code**\n",
        "   - Pastikan **setiap pemeriksaan tersebut** memiliki **output pada cell-nya**. Jika tidak **submission langsung ditolak**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKeejtvxM6X1"
      },
      "outputs": [],
      "source": [
        "df_clean = df.copy()\n",
        "missing_values = df_clean.isnull().sum().sort_values(ascending=False)\n",
        "missing_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RrBA92mpHBc"
      },
      "outputs": [],
      "source": [
        "duplicate_count = df_clean.duplicated().sum()\n",
        "duplicate_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7WXozOgpJp-"
      },
      "outputs": [],
      "source": [
        "numeric_cols = df_clean.select_dtypes(include='number').columns.tolist()\n",
        "continuous_features = numeric_cols.copy()\n",
        "numeric_scaler = StandardScaler()\n",
        "df_clean[numeric_cols] = numeric_scaler.fit_transform(df_clean[numeric_cols])\n",
        "df_clean[numeric_cols].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGLR0NTwsMOp"
      },
      "outputs": [],
      "source": [
        "id_columns = ['TransactionID', 'AccountID', 'DeviceID', 'IP Address', 'MerchantID']\n",
        "df_clean = df_clean.drop(columns=[col for col in id_columns if col in df_clean.columns])\n",
        "df_clean.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eycdNMQqx4c"
      },
      "outputs": [],
      "source": [
        "categorical_cols = df_clean.select_dtypes(include='object').columns.tolist()\n",
        "label_encoders = {}\n",
        "if categorical_cols:\n",
        "    for col in categorical_cols:\n",
        "        encoder = LabelEncoder()\n",
        "        df_clean[col] = encoder.fit_transform(df_clean[col].astype(str))\n",
        "        label_encoders[col] = encoder\n",
        "    df_clean[categorical_cols].head()\n",
        "else:\n",
        "    print('Tidak ada fitur kategorikal untuk diencode.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1EmlGmZCCAP"
      },
      "outputs": [],
      "source": [
        "df_clean.columns.tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnbH2l_wv9l8"
      },
      "source": [
        "(Opsional) Pembersihan dan Pra Pemrosesan Data [Skilled]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria skilled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UoGhAUrsxIV"
      },
      "outputs": [],
      "source": [
        "if continuous_features:\n",
        "    df_clean[continuous_features] = df_clean[continuous_features].fillna(0)\n",
        "\n",
        "if 'categorical_cols' in globals() and categorical_cols:\n",
        "    for col in categorical_cols:\n",
        "        mode = df_clean[col].mode()\n",
        "        if not mode.empty:\n",
        "            df_clean[col] = df_clean[col].fillna(mode.iloc[0])\n",
        "\n",
        "df_clean.isnull().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGt2XApTttSL"
      },
      "outputs": [],
      "source": [
        "rows_before = df_clean.shape[0]\n",
        "df_clean = df_clean.drop_duplicates().reset_index(drop=True)\n",
        "duplicates_removed = rows_before - df_clean.shape[0]\n",
        "duplicates_removed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5RrswThwQrC"
      },
      "source": [
        "(Opsional) Pembersihan dan Pra Pemrosesan Data [Advanced]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria advanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvhfyYpat9Xs"
      },
      "outputs": [],
      "source": [
        "outliers_removed = 0\n",
        "if continuous_features:\n",
        "    outlier_mask = pd.Series(False, index=df_clean.index)\n",
        "    for col in continuous_features:\n",
        "        q1, q3 = df_clean[col].quantile([0.25, 0.75])\n",
        "        iqr = q3 - q1\n",
        "        lower_bound = q1 - 1.5 * iqr\n",
        "        upper_bound = q3 + 1.5 * iqr\n",
        "        outlier_mask |= (df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)\n",
        "    outliers_removed = int(outlier_mask.sum())\n",
        "    df_clean = df_clean.loc[~outlier_mask].reset_index(drop=True)\n",
        "outliers_removed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjcR-3G0u-GL"
      },
      "outputs": [],
      "source": [
        "binning_config = {'TransactionAmount': 4, 'CustomerAge': 3}\n",
        "bin_columns = []\n",
        "for col, bins in binning_config.items():\n",
        "    if col in df_clean.columns:\n",
        "        bin_col = f'{col}_bin'\n",
        "        binned = pd.qcut(df_clean[col], q=bins, duplicates='drop')\n",
        "        df_clean[bin_col] = binned.astype(str)\n",
        "        encoder = LabelEncoder()\n",
        "        df_clean[bin_col] = encoder.fit_transform(df_clean[bin_col])\n",
        "        label_encoders[bin_col] = encoder\n",
        "        bin_columns.append(bin_col)\n",
        "        if 'categorical_cols' in globals() and bin_col not in categorical_cols:\n",
        "            categorical_cols.append(bin_col)\n",
        "if bin_columns:\n",
        "    df_clean[bin_columns].head()\n",
        "else:\n",
        "    print('Tidak ada fitur yang dibinning.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fkd_QHXWMBDr"
      },
      "source": [
        "# **4. Membangun Model Clustering**\n",
        "Pada tahap ini, Anda membangun model clustering dengan memilih algoritma yang sesuai untuk mengelompokkan data berdasarkan kesamaan.\n",
        "1. Pastikan Anda menggunakan dataframe yang sudah melalui processing sesuai dengan levelnya (Basic, Skilled, Advanced)\n",
        "2. Melakukan visualisasi Elbow Method untuk menentukan jumlah cluster terbaik menggunakan `KElbowVisualizer()`.\n",
        "3. Menggunakan algoritma K-Means Clustering dengan `sklearn.cluster.KMeans()`.\n",
        "4. Jalankan cell code `joblib.dump(model_kmeans, \"model_clustering.h5\")` untuk menyimpan model yang sudah dibuat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYHmRnb42A1P"
      },
      "outputs": [],
      "source": [
        "df_clean.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgYvwWOzM93L"
      },
      "outputs": [],
      "source": [
        "X_clustering = df_clean.copy()\n",
        "\n",
        "elbow_model = KMeans(random_state=42, n_init=10)\n",
        "elbow_visualizer = KElbowVisualizer(\n",
        "    elbow_model,\n",
        "    k=(2, 10),\n",
        "    metric=\"distortion\",\n",
        "    timings=False,\n",
        ")\n",
        "elbow_visualizer.fit(X_clustering)\n",
        "elbow_visualizer.show()\n",
        "optimal_k = elbow_visualizer.elbow_value_\n",
        "if optimal_k is None:\n",
        "    optimal_k = 4\n",
        "print(f\"Optimal number of clusters based on Elbow Method: {int(optimal_k)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvngRg-r4EcL"
      },
      "outputs": [],
      "source": [
        "best_k = int(optimal_k)\n",
        "model_kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
        "model_kmeans.fit(X_clustering)\n",
        "cluster_labels = model_kmeans.labels_\n",
        "df_clustered = df_clean.copy()\n",
        "df_clustered['Target'] = cluster_labels\n",
        "df_clustered.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aVHlHyU1Dcx"
      },
      "source": [
        "Jalankan cell code ini untuk menyimpan model kamu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7AvYmQnY_fI"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model_kmeans, \"model_clustering.h5\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDOD9eVMx3mC"
      },
      "source": [
        "(Opsional) Membangun Model Clustering [Skilled]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria skilled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SELNsH5O4Oyn"
      },
      "outputs": [],
      "source": [
        "silhouette = silhouette_score(X_clustering, cluster_labels)\n",
        "print(f\"Silhouette Score: {silhouette:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4EbkaXg4QAN"
      },
      "outputs": [],
      "source": [
        "pca_visual = PCA(n_components=2)\n",
        "components_2d = pca_visual.fit_transform(X_clustering)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "scatter = ax.scatter(\n",
        "    components_2d[:, 0],\n",
        "    components_2d[:, 1],\n",
        "    c=cluster_labels,\n",
        "    cmap='tab10',\n",
        "    s=35,\n",
        "    alpha=0.7,\n",
        "    edgecolor='k',\n",
        "    linewidth=0.2,\n",
        ")\n",
        "ax.set_title('K-Means Clusters (PCA Projection)')\n",
        "ax.set_xlabel('PCA 1')\n",
        "ax.set_ylabel('PCA 2')\n",
        "legend = ax.legend(*scatter.legend_elements(), loc='best')\n",
        "ax.add_artist(legend)\n",
        "plt.tight_layout()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uloMRbnsyAbB"
      },
      "source": [
        "(Opsional) Membangun Model Clustering [Advanced]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria advanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgfOarXX4SD2"
      },
      "outputs": [],
      "source": [
        "pca_components = 2\n",
        "pca_model = PCA(n_components=pca_components)\n",
        "pca_transformed = pca_model.fit_transform(X_clustering)\n",
        "PCA_2 = pd.DataFrame(\n",
        "    pca_transformed,\n",
        "    columns=[f\"PCA{i+1}\" for i in range(pca_components)],\n",
        ")\n",
        "model_kmeans_pca = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
        "model_kmeans_pca.fit(PCA_2)\n",
        "pca_pipeline = Pipeline(\n",
        "    steps=[\n",
        "        (\"pca\", PCA(n_components=pca_components)),\n",
        "        (\"kmeans\", KMeans(n_clusters=best_k, random_state=42, n_init=10)),\n",
        "    ]\n",
        ")\n",
        "pca_pipeline.fit(X_clustering)\n",
        "PCA_2.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKvJy9Ky4VB3"
      },
      "outputs": [],
      "source": [
        "joblib.dump(pca_pipeline, \"PCA_model_clustering.h5\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anlTI9Trb7F6"
      },
      "source": [
        "# **5. Interpretasi Cluster**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfgVMEBDS3KG"
      },
      "source": [
        "## **a. Interpretasi Hasil Clustering**\n",
        "1. **Contoh Interpretasi:**\n",
        "- **Cluster 1: (Nasabah Bertransaksi dan Pendapatan Besar)**:\n",
        "  - **Rata-rata (mean) Annual Income:** 0.953 (48,260)\n",
        "  - **Rata-rata (mean) Spending Score:** 0.8 (56.48)\n",
        "  - **Analisis:** Cluster ini mencakup pelanggan dengan pendapatan tahunan tinggi dan tingkat pengeluaran yang cukup tinggi. Pelanggan dalam cluster ini cenderung memiliki daya beli yang tinggi dan mereka lebih cenderung untuk membelanjakan sebagian besar pendapatan mereka. Sehingga rekomendasi pada kelompok nasabah ini adalah dengan menawarkan produk-produk investasi atau perbankan yang berkualitas tinggi.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmpy4fmV64Mi"
      },
      "outputs": [],
      "source": [
        "numeric_features = [col for col in df_clustered.select_dtypes(include='number').columns if col != 'Target']\n",
        "if numeric_features:\n",
        "    cluster_numeric_summary = (\n",
        "        df_clustered.groupby('Target')[numeric_features]\n",
        "        .agg(['mean', 'min', 'max'])\n",
        "        .round(3)\n",
        "    )\n",
        "    cluster_numeric_summary\n",
        "else:\n",
        "    print('Tidak ada fitur numerik yang dapat dianalisis untuk setiap cluster.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrjMI_dG6tnb"
      },
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "if 'cluster_numeric_summary' in globals():\n",
        "    mean_values = cluster_numeric_summary.xs('mean', axis=1, level=1)\n",
        "    summary_lines = []\n",
        "    for cluster_id, means in mean_values.iterrows():\n",
        "        high_features = means.sort_values(ascending=False).head(3)\n",
        "        low_features = means.sort_values().head(2)\n",
        "        high_desc = ', '.join([f\"{feature} ({value:.2f})\" for feature, value in high_features.items()])\n",
        "        low_desc = ', '.join([f\"{feature} ({value:.2f})\" for feature, value in low_features.items()])\n",
        "        summary_lines.append(\n",
        "            f\"**Cluster {cluster_id}** → nilai standar relatif tinggi pada {high_desc} dan cenderung rendah pada {low_desc}.\"\n",
        "        )\n",
        "    display(\n",
        "        Markdown(\n",
        "            ''.join(\n",
        "                ['### Ringkasan Profil Cluster (Skala Terstandardisasi)',\n",
        "                 'Interpretasi menggunakan nilai mean (standar) untuk mengidentifikasi fitur yang menonjol pada tiap cluster.'] +\n",
        "                [f\"- {line}\" for line in summary_lines]\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "else:\n",
        "    display(Markdown('Ringkasan numerik belum tersedia karena sel sebelumnya belum dijalankan.'))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaYP1fx5VgWO"
      },
      "source": [
        "# **6. Mengeksport Data**\n",
        "\n",
        "1. Simpan nama kolom hasil clustering dengan nama `Target`.\n",
        "2. Simpan hasilnya ke dalam file CSV menggunakan function `to_csv()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FInN10U5S4f"
      },
      "outputs": [],
      "source": [
        "if 'Target' not in df_clustered.columns:\n",
        "    raise ValueError('Kolom Target belum tersedia pada dataframe hasil clustering.')\n",
        "\n",
        "cluster_counts = df_clustered['Target'].value_counts().sort_index()\n",
        "cluster_counts\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkbg_o80aRSH"
      },
      "outputs": [],
      "source": [
        "data_clustering_path = Path('data_clustering.csv')\n",
        "df_clustered.to_csv(data_clustering_path, index=False)\n",
        "print(f'Data hasil clustering tersimpan pada {data_clustering_path.resolve().name} dengan {df_clustered.shape[0]} baris.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rz1vFc2yzFPD"
      },
      "source": [
        "(Opsional) Interpretasi Hasil Clustering [Skilled]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria skilled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMcRV15y_hH3"
      },
      "outputs": [],
      "source": [
        "df_inverse = df_clustered.copy()\n",
        "if continuous_features:\n",
        "    numeric_for_inverse = [col for col in continuous_features if col in df_inverse.columns]\n",
        "    if numeric_for_inverse:\n",
        "        df_inverse[numeric_for_inverse] = numeric_scaler.inverse_transform(df_inverse[numeric_for_inverse])\n",
        "df_inverse.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzIddcB6XjrC"
      },
      "outputs": [],
      "source": [
        "if label_encoders:\n",
        "    for col, encoder in label_encoders.items():\n",
        "        if col in df_inverse.columns:\n",
        "            df_inverse[col] = encoder.inverse_transform(df_inverse[col].astype(int))\n",
        "df_inverse.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omCabiXBTklU"
      },
      "outputs": [],
      "source": [
        "numeric_original_cols = [col for col in df_inverse.select_dtypes(include='number').columns if col != 'Target']\n",
        "categorical_original_cols = [col for col in df_inverse.select_dtypes(exclude='number').columns]\n",
        "\n",
        "if numeric_original_cols:\n",
        "    inverse_numeric_summary = (\n",
        "        df_inverse.groupby('Target')[numeric_original_cols]\n",
        "        .agg(['mean', 'min', 'max'])\n",
        "        .round(2)\n",
        "    )\n",
        "    display(inverse_numeric_summary)\n",
        "else:\n",
        "    print('Tidak ada fitur numerik untuk dianalisis setelah proses inverse.')\n",
        "\n",
        "if categorical_original_cols:\n",
        "    def mode_or_first(series):\n",
        "        mode = series.mode()\n",
        "        if not mode.empty:\n",
        "            return mode.iloc[0]\n",
        "        return series.iloc[0]\n",
        "\n",
        "    inverse_categorical_summary = (\n",
        "        df_inverse.groupby('Target')[categorical_original_cols]\n",
        "        .agg(mode_or_first)\n",
        "    )\n",
        "    display(inverse_categorical_summary)\n",
        "else:\n",
        "    print('Tidak ada fitur kategorikal untuk dianalisis setelah proses inverse.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcaT8sxVzLs6"
      },
      "source": [
        "summary_lines_inverse = []\n",
        "if 'inverse_numeric_summary' in globals():\n",
        "    mean_original = inverse_numeric_summary.xs('mean', axis=1, level=1)\n",
        "    for cluster_id, means in mean_original.iterrows():\n",
        "        top_high = means.sort_values(ascending=False).head(2)\n",
        "        top_low = means.sort_values().head(2)\n",
        "        high_text = ', '.join([f\"{feature} ≈ {value:,.2f}\" for feature, value in top_high.items()])\n",
        "        low_text = ', '.join([f\"{feature} ≈ {value:,.2f}\" for feature, value in top_low.items()])\n",
        "\n",
        "        cat_text = ''\n",
        "        if 'inverse_categorical_summary' in globals():\n",
        "            cat_values = inverse_categorical_summary.loc[cluster_id]\n",
        "            formatted = [f\"{col}: {val}\" for col, val in cat_values.items()]\n",
        "            cat_text = f\"; fitur kategorikal dominan → {', '.join(formatted)}\"\n",
        "\n",
        "        summary_lines_inverse.append(\n",
        "            f\"Cluster {cluster_id}: fitur numerik tinggi pada {high_text}; lebih rendah pada {low_text}{cat_text}.\"\n",
        "        )\n",
        "\n",
        "if summary_lines_inverse:\n",
        "    display(\n",
        "        Markdown(\n",
        "            ''.join(\n",
        "                ['### Interpretasi Cluster pada Skala Asli'] +\n",
        "                [f\"- {line}\" for line in summary_lines_inverse]\n",
        "            )\n",
        "        )\n",
        "    )\n",
        "else:\n",
        "    display(Markdown('Jalankan sel sebelumnya untuk mendapatkan ringkasan interpretasi cluster.'))\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSd6vZslzatv"
      },
      "source": [
        "(Opsional) Interpretasi Hasil Clustering [Advanced]\n",
        "\n",
        "**Biarkan kosong jika tidak menerapkan kriteria advanced**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mGIyUZ2zRCP"
      },
      "outputs": [],
      "source": [
        "df_inverse_with_target = df_inverse.copy()\n",
        "ordered_columns = [col for col in df.columns if col in df_inverse_with_target.columns]\n",
        "ordered_columns += [col for col in df_inverse_with_target.columns if col not in ordered_columns]\n",
        "df_inverse_with_target = df_inverse_with_target[ordered_columns]\n",
        "df_inverse_with_target.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEASz_Q__jms"
      },
      "outputs": [],
      "source": [
        "data_inverse_path = Path('data_clustering_inverse.csv')\n",
        "df_inverse_with_target.to_csv(data_inverse_path, index=False)\n",
        "print(f'Data inverse dengan label cluster tersimpan pada {data_inverse_path.resolve().name}.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWOK6TDTL0eH"
      },
      "source": [
        "End of Code."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}